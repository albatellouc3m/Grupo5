{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *MODELO FINAL*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Selección del Mejor Modelo\n",
    "Tras evaluar distintos modelos (KNN, Árboles de Decisión, Regresión Logística, SVM, etc) se comprobó que el SVM con Kernel RBF y los hiperparámetros óptimos:\n",
    "* C=10\n",
    "* gamma = 'scale'\n",
    "* kernel = 'rbf'\n",
    "\n",
    "presenta el mejor desempeño en términos de Balanced Accuracy en el conjunto de validación interna. Esto lo convierte en nuestro candidato para el modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluación Outer y Estimación del Desempeño futuro\n",
    "La estrategia de evaluación outer consiste en separar los datos en dos partes:\n",
    "\n",
    "* Train (2/3): Para realizar el ajuste y selección de modelos\n",
    "* Test (1/3): Para obtener una estimación real de rendimiento que tendría el modelo en una competición\n",
    "\n",
    "Aunque durante la práctica se ha usado esta partición para evaluar el desempeño, en el paso final se reentrena al modelo usando todos los datos disponibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado.\n",
      "Accediendo a través de best_estimator_\n",
      "\n",
      "Pasos encontrados en el pipeline:\n",
      "{'imputer': SimpleImputer(), 'scaler': RobustScaler(), 'svm': SVC(C=10)}\n",
      "\n",
      "Nombres de los pasos disponibles (claves):\n",
      "['imputer', 'scaler', 'svm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RobustScaler from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator GridSearchCV from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder # Añade los imports necesarios si ejecutas esto por separado\n",
    "\n",
    "# Carga el modelo\n",
    "modelo_final = joblib.load('modelo_final.pkl')\n",
    "print(\"Modelo cargado.\")\n",
    "\n",
    "# Accede al pipeline (asumiendo que es un best_estimator_ de GridSearch/RandomizedSearch)\n",
    "# Si tu modelo guardado ES el pipeline directamente, quita .best_estimator_\n",
    "try:\n",
    "    if hasattr(modelo_final, 'best_estimator_'):\n",
    "        pipeline_real = modelo_final.best_estimator_\n",
    "        print(\"Accediendo a través de best_estimator_\")\n",
    "    else:\n",
    "        pipeline_real = modelo_final # Asume que el objeto guardado es el pipeline\n",
    "        print(\"Accediendo directamente al objeto cargado.\")\n",
    "\n",
    "    # Verifica si es un pipeline y muestra los pasos\n",
    "    if hasattr(pipeline_real, 'named_steps'):\n",
    "        print(\"\\nPasos encontrados en el pipeline:\")\n",
    "        print(pipeline_real.named_steps)\n",
    "        print(\"\\nNombres de los pasos disponibles (claves):\")\n",
    "        print(list(pipeline_real.named_steps.keys()))\n",
    "    else:\n",
    "        print(f\"\\nEl objeto ({type(pipeline_real)}) no parece ser un Pipeline de scikit-learn (no tiene 'named_steps').\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcurrió un error al inspeccionar el modelo: {e}\")\n",
    "    print(\"Asegúrate de que 'modelo_final.pkl' contiene el objeto esperado (posiblemente un Pipeline o resultado de GridSearchCV).\")\n",
    "\n",
    "# ---- Aquí continuaría tu código original ----\n",
    "# ... (carga de datos_test, preprocesamiento, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Generación de Predicciones para la Competición\n",
    "El siguiente paso es utilizar el modelo final para generar predicciones sobre el conjunto de datos de la competición. Para ello se debe aplicar el mismo preprocesado que a los datos de entrenamiento. El fichero resultante se guardará como predicciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales de entrenamiento cargados para ajustar el preprocesador.\n",
      "\n",
      "Generando predicciones...\n",
      "\n",
      "Distribución de predicciones:\n",
      "Attrition\n",
      "No     1236\n",
      "Yes     234\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Predicciones guardadas en 'predicciones.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RobustScaler from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/alba/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator GridSearchCV from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Importar los datos de entrenamiento\n",
    "datos_generales_originales = pd.read_csv('./attrition_availabledata_10.csv.gz')\n",
    "print(\"Datos originales de entrenamiento cargados para ajustar el preprocesador.\")\n",
    "\n",
    "\n",
    "# Para el conjunto de competición, eliminamos las mismas columnas que eliminamos en el entrenamiento\n",
    "datos_generales_originales['Attrition'] = datos_generales_originales['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "X_entrenamiento = datos_generales_originales.drop(columns=['Attrition', 'EmployeeID', 'Over18', 'EmployeeCount', 'StandardHours'])\n",
    "\n",
    "# Redefinir y AJUSTAR el ColumnTransformer \n",
    "categorical_features = ['Department', 'JobRole', 'EducationField']\n",
    "ordinal_features = ['BusinessTravel', 'Gender', 'MaritalStatus']\n",
    "# numerical_features = X_entrenamiento.select_dtypes(include=['int64','float64']).columns.tolist() # No se usa explícitamente aquí\n",
    "valores_ordinales = [\n",
    "    ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'],   # BusinessTravel\n",
    "    ['Male', 'Female'],                                     # Gender\n",
    "    ['Single', 'Married', 'Divorced']                       # MaritalStatus \n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features), # Añadido handle_unknown por seguridad\n",
    "        ('ord', OrdinalEncoder(categories=valores_ordinales, handle_unknown='use_encoded_value', unknown_value=-1), ordinal_features) # Añadido manejo de desconocidos\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "# Ajustamos el preprocesador con TODOS los datos de X \n",
    "preprocessor.fit(X_entrenamiento)\n",
    "\n",
    "# --- PASO 2: Cargar datos de competición y modelo final ---\n",
    "datos_test_competicion = pd.read_csv('./attrition_competition_10.csv.gz')\n",
    "modelo_final = joblib.load('modelo_final.pkl') # Warnings de versión aparecerán aquí\n",
    "\n",
    "\n",
    "# reparar datos de competición \n",
    "columnas_a_eliminar_test = [\"EmployeeID\", \"EmployeeCount\", \"Over18\", \"StandardHours\"]\n",
    "# Asegúrate de que datos_test_competicion exista y sea el DataFrame correcto\n",
    "datos_test_competicion_limpios = datos_test_competicion.drop(columns=columnas_a_eliminar_test)\n",
    "# No eliminamos 'Attrition' aquí porque no existe en los datos de competición\n",
    "\n",
    "# Aplicar el preprocesador ajustado a los datos de competición\n",
    "datos_test_transformados = preprocessor.transform(datos_test_competicion_limpios)\n",
    "\n",
    "# Convertir a DataFrame para facilitar la manipulación\n",
    "columnas_prefijadas = preprocessor.get_feature_names_out()\n",
    "datos_test_listos_para_predecir = pd.DataFrame(datos_test_transformados, columns=columnas_prefijadas)\n",
    "\n",
    "# --- PASO 3: Generar Predicciones ---\n",
    "print(\"\\nGenerando predicciones...\")\n",
    "\n",
    "# Pasamos el DataFrame con los nombres de columna CORRECTOS (prefijados)\n",
    "y_pred_test = modelo_final.predict(datos_test_listos_para_predecir)\n",
    "\n",
    "# Creamos un DataFrame con las predicciones y el EmployeeID original\n",
    "df_predicciones = pd.DataFrame({\n",
    "    'EmployeeID': datos_test_competicion['EmployeeID'], # Usamos el ID original\n",
    "    'Attrition': y_pred_test # La columna de predicción\n",
    "})\n",
    "\n",
    "# Mapeamos de nuevo a 'Yes'/'No' si es necesario para el formato de salida\n",
    "df_predicciones['Attrition'] = df_predicciones['Attrition'].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "print(f\"\\nDistribución de predicciones:\\n{df_predicciones['Attrition'].value_counts()}\")\n",
    "\n",
    "# Guardar las predicciones\n",
    "output_filename = \"predicciones.csv\"\n",
    "df_predicciones.to_csv(output_filename, index=False)\n",
    "print(f\"\\nPredicciones guardadas en '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tarea Adicional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta tarea adicional, hemos decicido utilizar la herramienta SHAP, para interpretar nuestro modelo final.\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) es una herramienta basada en la teoría de juegos que permite cuantificar la contribución de cada variable a la predicción de un modelo. Entre sus principales ventajas destacan:\n",
    "\n",
    "* **Interpretabilidad Local y Global**: SHAP ofrece explicaciones tanto a nuvel individual (por cada predicción) como a nivel global (importancia de las variables a lo largo de todo el conjunto). Esto permite identificar cómo cada característica influye en cada decisión del modelo.\n",
    "\n",
    "* **Consistencia y solidez**: Los valores de Shapley garantizan que la contribución de cada característica se mida de forma justa, lo que otorga una interpretación coherente y consistente.\n",
    "\n",
    "* **Modelo-agnóstico**: A diferencia de otros métodos que se basan en la estructura interna del modelo (por ejemplo, la importancia basada en la impureza de los árboles en RandomForest), SHAP puede aplicarse a cualquier modelo.\n",
    "\n",
    "* **Transparencia**: Integrar SHAP en el análisis del modelo permite detectar posibles sesgos o relaciones inesperadas entre variables, lo cual es fundamental para generar confianza en la toma de decisiones basadas en inteligencia artificial.\n",
    "\n",
    "Realizar esta tarea extra con SHAP resulta especialmente interesante en comparación con construir otro modelo como un RandomForest o una red neuronal. Aunque estos modelos pueden ofrecer buenos resultados, la interpretación de sus resultados (por ejemplo, mediante la importancia de variables basada en el Gini o técnicas de regularización) suele ser menos precisa y profunda. En cambio, al interpretar el modelo SVM seleccionado con SHAP, se obtiene una explicación detallada y cuantitativa de la influencia de cada característica en la predicción, lo cual añade un valor extra al análisis, especialmente en contextos donde la explicabilidad es crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Código para usar SHAP en nuestro modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Seleccionar una muestra representativa del conjunto preprocesado para el fondo (background)\n",
    "# Reducir el tamaño del fondo para acelerar el cálculo\n",
    "X_background = X_preprocessed.sample(20, random_state=42)\n",
    "\n",
    "# Definir la función de predicción asegurándonos de que se pasan los nombres de las columnas\n",
    "def model_predict(data):\n",
    "    # Convertir a DataFrame si es necesario\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data, columns=columnas_preprocesadas)\n",
    "    return final_pipeline.predict_proba(data)[:, 1]\n",
    "\n",
    "# Crear el explicador con KernelExplainer usando el fondo reducido\n",
    "explainer = shap.KernelExplainer(model_predict, X_background)\n",
    "\n",
    "# Seleccionar un subconjunto reducido de datos para explicar\n",
    "X_explain = X_preprocessed.sample(10, random_state=42)\n",
    "\n",
    "# Calcular los valores SHAP para el subconjunto seleccionado, limitando nsamples para acelerar el proceso\n",
    "shap_values = explainer.shap_values(X_explain, nsamples=50)\n",
    "\n",
    "# Visualizar el resumen de los valores SHAP para identificar la importancia de las variables\n",
    "shap.summary_plot(shap_values, X_explain, feature_names=columnas_preprocesadas)\n",
    "plt.show()\n",
    "\n",
    "# Explicación local de una instancia en particular\n",
    "i = 0  # índice de la instancia a explicar\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[i], X_explain.iloc[i], feature_names=columnas_preprocesadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gráfica SHAP permite ver qué variables han influido más en las predicciones del modelo SVM sobre la variable Attrition. También muestra cómo valores altos o bajos de cada variable afectan individualmente a cada empleado.\n",
    "\n",
    "En este caso, la variable más influyente es remainder__TotalWorkingYears, lo que indica que el número total de años trabajados es clave en la decisión. Empleados con más años suelen tener valores SHAP negativos, lo que reduce la probabilidad de abandono. También destacan variables como remainder__hrs, DistanceFromHome o TrainingTimesLastYear. Por ejemplo, empleados que viven lejos tienden a tener más probabilidad de dejar la empresa, mientras que recibir más formación puede asociarse a menor riesgo.\n",
    "\n",
    "Las variables categóricas como el estado civil o el rol profesional (JobRole_Manager, MaritalStatus) también influyen, aunque en menor medida. Tener un cargo alto o estar casado parece relacionarse con mayor estabilidad.\n",
    "\n",
    "En general, el gráfico muestra que la experiencia, la distancia al trabajo y otros factores numéricos son los que más afectan al resultado. Se observan patrones coherentes: valores altos en algunas variables empujan la predicción hacia Attrition = 1, mientras que en otras hacen lo contrario. Esto permite confiar más en el modelo y entender mejor sus decisiones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
