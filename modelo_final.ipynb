{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *MODELO FINAL*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Selección del Mejor Modelo\n",
    "Tras evaluar distintos modelos (KNN, Árboles de Decisión, Regresión Logística, SVM, etc) se comprobó que el SVM con Kernel RBF y los hiperparámetros óptimos:\n",
    "* C=10\n",
    "* gamma = 'scale'\n",
    "* kernel = 'rbf'\n",
    "\n",
    "presenta el mejor desempeño en términos de Balanced Accuracy en el conjunto de validación interna. Esto lo convierte en nuestro candidato para el modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluación Outer y Estimación del Desempeño futuro\n",
    "La estrategia de evaluación outer consiste en separar los datos en dos partes:\n",
    "\n",
    "* Train (2/3): Para realizar el ajuste y selección de modelos\n",
    "* Test (1/3): Para obtener una estimación real de rendimiento que tendría el modelo en una competición\n",
    "\n",
    "Aunque durante la práctica se ha usado esta partición para evaluar el desempeño, en el paso final se reentrena al modelo usando todos los datos disponibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Generación de Predicciones para la Competición\n",
    "El siguiente paso es utilizar el modelo final para generar predicciones sobre el conjunto de datos de la competición. Para ello se debe aplicar el mismo preprocesado que a los datos de entrenamiento. El fichero resultante se guardará como predicciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de test cargados y modelo final importado.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'knn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m datos_test_preprocessed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([categorical_encoded_df, ordinal_encoded_df, numeric_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Asegurarnos de que las columnas coincidan con las esperadas por el modelo\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Obtenemos las columnas esperadas directamente del modelo\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m expected_columns \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mknn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfeature_names_in_\n\u001b[1;32m     47\u001b[0m datos_test_preprocessed \u001b[38;5;241m=\u001b[39m datos_test_preprocessed[expected_columns]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompletado - Preprocesamiento de Datos.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/utils/_bunch.py:39\u001b[0m, in \u001b[0;36mBunch.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_deprecated_key_to_warnings\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}):\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deprecated_key_to_warnings[key],\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m     )\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'knn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Importamos los datos de test y el modelo final\n",
    "datos_test = pd.read_csv('./attrition_competition_10.csv.gz')\n",
    "modelo_final = joblib.load('modelo_final.pkl')\n",
    "\n",
    "print(\"Datos de test cargados y modelo final importado.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4.1. Preprocesamiento Manual de los Datos de la Competición\n",
    "# ---------------------------\n",
    "# Para el conjunto de competición, eliminamos las mismas columnas que en el entrenamiento.\n",
    "datos_test = datos_test.drop(columns=[\"EmployeeID\", \"EmployeeCount\", \"Over18\", \"StandardHours\"])\n",
    "datos_test = datos_test.drop(columns=[\"Attrition\"], errors='ignore')\n",
    "\n",
    "# Variables categóricas y ordinales (debes definirlas como en el entrenamiento)\n",
    "categorical_features = ['Department', 'JobRole', 'EducationField']\n",
    "ordinal_features = ['BusinessTravel', 'Gender', 'MaritalStatus']\n",
    "valores_ordinales = [\n",
    "    ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'],  # Para BusinessTravel\n",
    "    ['Male', 'Female'],                                   # Para Gender\n",
    "    ['Single', 'Married', 'Divorced']                     # Para MaritalStatus\n",
    "]\n",
    "\n",
    "# OneHotEncoding para variables categóricas\n",
    "onehot_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "categorical_encoded = onehot_encoder.fit_transform(datos_test[categorical_features])\n",
    "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=onehot_encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# OrdinalEncoding para variables ordinales\n",
    "ordinal_encoder = OrdinalEncoder(categories=valores_ordinales)\n",
    "ordinal_encoded = ordinal_encoder.fit_transform(datos_test[ordinal_features])\n",
    "ordinal_encoded_df = pd.DataFrame(ordinal_encoded, columns=ordinal_features)\n",
    "\n",
    "# Mantener el resto de las columnas (numéricas)\n",
    "numeric_features = datos_test.drop(columns=categorical_features + ordinal_features).columns\n",
    "numeric_df = datos_test[numeric_features].reset_index(drop=True)\n",
    "\n",
    "# Concatenar todas las columnas preprocesadas\n",
    "datos_test_preprocessed = pd.concat([categorical_encoded_df, ordinal_encoded_df, numeric_df], axis=1)\n",
    "\n",
    "# Asegurarnos de que las columnas coincidan con las esperadas por el modelo\n",
    "# Obtenemos las columnas esperadas directamente del modelo\n",
    "expected_columns = modelo_final.best_estimator_.named_steps['knn'].feature_names_in_\n",
    "datos_test_preprocessed = datos_test_preprocessed[expected_columns]\n",
    "\n",
    "print(\"Completado - Preprocesamiento de Datos.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4.2. Generar Predicciones\n",
    "# ---------------------------\n",
    "# Generamos predicciones con el modelo entrenado\n",
    "y_pred_test = modelo_final.predict(datos_test_preprocessed)\n",
    "\n",
    "# Creamos un DataFrame con las predicciones\n",
    "df_predicciones = pd.DataFrame(y_pred_test, columns=[\"Predicción\"])\n",
    "\n",
    "print(df_predicciones[\"Predicción\"].value_counts())  # Mostramos un mensaje por pantalla, predicciones realizadas\n",
    "df_predicciones.to_csv(\"predicciones.csv\", index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tarea Adicional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta tarea adicional, hemos decicido utilizar la herramienta SHAP, para interpretar nuestro modelo final.\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) es una herramienta basada en la teoría de juegos que permite cuantificar la contribución de cada variable a la predicción de un modelo. Entre sus principales ventajas destacan:\n",
    "\n",
    "* **Interpretabilidad Local y Global**: SHAP ofrece explicaciones tanto a nuvel individual (por cada predicción) como a nivel global (importancia de las variables a lo largo de todo el conjunto). Esto permite identificar cómo cada característica influye en cada decisión del modelo.\n",
    "\n",
    "* **Consistencia y solidez**: Los valores de Shapley garantizan que la contribución de cada característica se mida de forma justa, lo que otorga una interpretación coherente y consistente.\n",
    "\n",
    "* **Modelo-agnóstico**: A diferencia de otros métodos que se basan en la estructura interna del modelo (por ejemplo, la importancia basada en la impureza de los árboles en RandomForest), SHAP puede aplicarse a cualquier modelo.\n",
    "\n",
    "* **Transparencia**: Integrar SHAP en el análisis del modelo permite detectar posibles sesgos o relaciones inesperadas entre variables, lo cual es fundamental para generar confianza en la toma de decisiones basadas en inteligencia artificial.\n",
    "\n",
    "Realizar esta tarea extra con SHAP resulta especialmente interesante en comparación con construir otro modelo como un RandomForest o una red neuronal. Aunque estos modelos pueden ofrecer buenos resultados, la interpretación de sus resultados (por ejemplo, mediante la importancia de variables basada en el Gini o técnicas de regularización) suele ser menos precisa y profunda. En cambio, al interpretar el modelo SVM seleccionado con SHAP, se obtiene una explicación detallada y cuantitativa de la influencia de cada característica en la predicción, lo cual añade un valor extra al análisis, especialmente en contextos donde la explicabilidad es crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Código para usar SHAP en nuestro modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Seleccionar una muestra representativa del conjunto preprocesado para el fondo (background)\n",
    "# Reducir el tamaño del fondo para acelerar el cálculo\n",
    "X_background = X_preprocessed.sample(20, random_state=42)\n",
    "\n",
    "# Definir la función de predicción asegurándonos de que se pasan los nombres de las columnas\n",
    "def model_predict(data):\n",
    "    # Convertir a DataFrame si es necesario\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data, columns=columnas_preprocesadas)\n",
    "    return final_pipeline.predict_proba(data)[:, 1]\n",
    "\n",
    "# Crear el explicador con KernelExplainer usando el fondo reducido\n",
    "explainer = shap.KernelExplainer(model_predict, X_background)\n",
    "\n",
    "# Seleccionar un subconjunto reducido de datos para explicar\n",
    "X_explain = X_preprocessed.sample(10, random_state=42)\n",
    "\n",
    "# Calcular los valores SHAP para el subconjunto seleccionado, limitando nsamples para acelerar el proceso\n",
    "shap_values = explainer.shap_values(X_explain, nsamples=50)\n",
    "\n",
    "# Visualizar el resumen de los valores SHAP para identificar la importancia de las variables\n",
    "shap.summary_plot(shap_values, X_explain, feature_names=columnas_preprocesadas)\n",
    "plt.show()\n",
    "\n",
    "# Explicación local de una instancia en particular\n",
    "i = 0  # índice de la instancia a explicar\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[i], X_explain.iloc[i], feature_names=columnas_preprocesadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gráfica SHAP permite ver qué variables han influido más en las predicciones del modelo SVM sobre la variable Attrition. También muestra cómo valores altos o bajos de cada variable afectan individualmente a cada empleado.\n",
    "\n",
    "En este caso, la variable más influyente es remainder__TotalWorkingYears, lo que indica que el número total de años trabajados es clave en la decisión. Empleados con más años suelen tener valores SHAP negativos, lo que reduce la probabilidad de abandono. También destacan variables como remainder__hrs, DistanceFromHome o TrainingTimesLastYear. Por ejemplo, empleados que viven lejos tienden a tener más probabilidad de dejar la empresa, mientras que recibir más formación puede asociarse a menor riesgo.\n",
    "\n",
    "Las variables categóricas como el estado civil o el rol profesional (JobRole_Manager, MaritalStatus) también influyen, aunque en menor medida. Tener un cargo alto o estar casado parece relacionarse con mayor estabilidad.\n",
    "\n",
    "En general, el gráfico muestra que la experiencia, la distancia al trabajo y otros factores numéricos son los que más afectan al resultado. Se observan patrones coherentes: valores altos en algunas variables empujan la predicción hacia Attrition = 1, mientras que en otras hacen lo contrario. Esto permite confiar más en el modelo y entender mejor sus decisiones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
