{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *MODELO FINAL*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Selección del Mejor Modelo\n",
    "Tras evaluar distintos modelos (KNN, Árboles de Decisión, Regresión Logística, SVM, etc) se comprobó que el SVM con Kernel RBF y los hiperparámetros óptimos:\n",
    "* C=10\n",
    "* gamma = 'scale'\n",
    "* kernel = 'rbf'\n",
    "\n",
    "presenta el mejor desempeño en términos de Balanced Accuracy en el conjunto de validación interna. Esto lo convierte en nuestro candidato para el modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluación Outer y Estimación del Desempeño futuro\n",
    "La estrategia de evaluación outer consiste en separar los datos en dos partes:\n",
    "\n",
    "* Train (2/3): Para realizar el ajuste y selección de modelos\n",
    "* Test (1/3): Para obtener una estimación real de rendimiento que tendría el modelo en una competición\n",
    "\n",
    "Aunque durante la práctica se ha usado esta partición para evaluar el desempeño, en el paso final se reentrena al modelo usando todos los datos disponibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Entrenamiento final y Guardado del Modelo\n",
    "En este paso se reentrena al modelo SVM Final utilizando todos los datos. Se aplica un preprocesado antes de entenar el clasificador. Finalmente guardamos el modelo en modelo_final.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final guardado en 'modelo_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ---------------------------\n",
    "# 3.1. Cargar y Preprocesar los Datos\n",
    "# ---------------------------\n",
    "# Cargamos los datos disponibles de entrenamiento y el dataset de competición\n",
    "datos_generales = pd.read_csv('./attrition_availabledata_10.csv.gz')\n",
    "datos_test = pd.read_csv('./attrition_competition_10.csv.gz')  # Datos para el test de la competición\n",
    "\n",
    "# Convertimos la variable objetivo a numérica: 'Yes' -> 1, 'No' -> 0\n",
    "datos_generales['Attrition'] = datos_generales['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Eliminamos columnas que no aportan información (IDs, columnas constantes, etc.)\n",
    "X = datos_generales.drop(columns=['Attrition', 'EmployeeID', 'Over18', 'EmployeeCount', 'StandardHours'])\n",
    "y = datos_generales['Attrition']\n",
    "\n",
    "# Definimos los nombres de variables según su tipo (estas definiciones se han usado en el preprocesado)\n",
    "categorical_features = ['Department', 'JobRole', 'EducationField']\n",
    "ordinal_features = ['BusinessTravel', 'Gender', 'MaritalStatus']\n",
    "# Nota: el resto de las variables numéricas se mantienen sin transformación adicional\n",
    "valores_ordinales = [\n",
    "    ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'],\n",
    "    ['Male', 'Female'],\n",
    "    ['Single', 'Married', 'Divorced']\n",
    "]\n",
    "\n",
    "# Creamos el preprocesador para transformar variables categóricas y ordinales\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),  # Variables categóricas sin orden\n",
    "        ('ord', OrdinalEncoder(categories=valores_ordinales), ordinal_features)  # Variables ordinales\n",
    "    ],\n",
    "    remainder='passthrough'  # El resto de variables (numéricas) se mantienen\n",
    ")\n",
    "\n",
    "# Aplicamos el preprocesado a todo el dataset de entrenamiento\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "# Obtenemos nombres de columnas tras la transformación para posibles análisis posteriores\n",
    "columnas_preprocesadas = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Convertimos el resultado a DataFrame (opcional, para visualización)\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed, columns=columnas_preprocesadas)\n",
    "\n",
    "# ---------------------------\n",
    "# 3.2. Entrenamiento del Modelo Final\n",
    "# ---------------------------\n",
    "# Definimos el pipeline final: imputación (por si acaso), escalado y SVM con hiperparámetros óptimos\n",
    "final_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(C=10, gamma='scale', kernel='rbf', probability=True))  # Se incluye probability=True si se requieren probabilidades\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo final con la totalidad de los datos preprocesados\n",
    "final_pipeline.fit(X_preprocessed, y)\n",
    "\n",
    "# Guardamos el modelo final en un fichero 'modelo_final.pkl'\n",
    "with open('modelo_final.pkl', 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "print(\"Modelo final guardado en 'modelo_final.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Generación de Predicciones para la Competición\n",
    "El siguiente paso es utilizar el modelo final para generar predicciones sobre el conjunto de datos de la competición. Para ello se debe aplicar el mismo preprocesado que a los datos de entrenamiento. El fichero resultante se guardará como predicciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones guardadas en 'predicciones.csv'\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 4.1. Preprocesamiento de los Datos de la Competición\n",
    "# ---------------------------\n",
    "# Para el conjunto de competición, eliminamos las mismas columnas que en el entrenamiento.\n",
    "# Se asume que el dataset de competición no contiene la variable 'Attrition'\n",
    "X_competicion = datos_test.drop(columns=['EmployeeID', 'Over18', 'EmployeeCount', 'StandardHours'])\n",
    "\n",
    "# Aplicamos el preprocesado usando el preprocessor ya ajustado (fit) en el conjunto de entrenamiento\n",
    "X_competicion_preprocessed = preprocessor.transform(X_competicion)\n",
    "# Convertimos a DataFrame para mayor claridad\n",
    "X_competicion_preprocessed = pd.DataFrame(X_competicion_preprocessed, columns=columnas_preprocesadas)\n",
    "\n",
    "# ---------------------------\n",
    "# 4.2. Generar Predicciones\n",
    "# ---------------------------\n",
    "# Utilizamos el modelo final para predecir las clases (o probabilidades si se requiere)\n",
    "predicciones = final_pipeline.predict(X_competicion_preprocessed)\n",
    "\n",
    "# Si se desea guardar además las probabilidades, se puede obtener:\n",
    "# prob_pred = final_pipeline.predict_proba(X_competicion_preprocessed)\n",
    "\n",
    "# Creamos un DataFrame con las predicciones\n",
    "df_predicciones = pd.DataFrame({\n",
    "    'Predicted_Attrition': predicciones\n",
    "})\n",
    "\n",
    "# Guardamos el DataFrame en un fichero CSV\n",
    "df_predicciones.to_csv('predicciones.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2940/2940 [4:39:29<00:00,  5.70s/it]      \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, category=\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[32m     18\u001b[39m shap_values = explainer.shap_values(X_preprocessed)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_preprocessed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/INGENIERÍA INFORMATICA/3er CURSO/2ndo CUATRI/aprendizaje automático/P1_AA/.venv/lib/python3.12/site-packages/shap/plots/_beeswarm.py:667\u001b[39m, in \u001b[36msummary_legacy\u001b[39m\u001b[34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale, rng)\u001b[39m\n\u001b[32m    662\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    663\u001b[39m             shape_msg + \u001b[33m\"\u001b[39m\u001b[33m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    664\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    665\u001b[39m         )\n\u001b[32m    666\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m num_features == features.shape[\u001b[32m1\u001b[39m], shape_msg\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    670\u001b[39m     feature_names = np.array([labels[\u001b[33m\"\u001b[39m\u001b[33mFEATURE\u001b[39m\u001b[33m\"\u001b[39m] % \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[31mAssertionError\u001b[39m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "X_background = shap.sample(X_preprocessed, 1, random_state=42)  # Toma 100 instancias al azar\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(\n",
    "    lambda x: final_pipeline.predict_proba(x),\n",
    "    X_background,\n",
    "    link=\"logit\"\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "shap_values = explainer.shap_values(X_preprocessed)\n",
    "\n",
    "shap.summary_plot(shap_values[1], X_preprocessed)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
