{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *MODELO FINAL*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Selección del Mejor Modelo\n",
    "Tras evaluar distintos modelos (KNN, Árboles de Decisión, Regresión Logística, SVM, etc) se comprobó que el SVM con Kernel RBF y los hiperparámetros óptimos:\n",
    "* C=10\n",
    "* gamma = 'scale'\n",
    "* kernel = 'rbf'\n",
    "\n",
    "presenta el mejor desempeño en términos de Balanced Accuracy en el conjunto de validación interna. Esto lo convierte en nuestro candidato para el modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Generación de Predicciones para la Competición\n",
    "El siguiente paso es utilizar el modelo final para generar predicciones sobre el conjunto de datos de la competición. Para ello se debe aplicar el mismo preprocesado que a los datos de entrenamiento. El fichero resultante se guardará como predicciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales de entrenamiento cargados para ajustar el preprocesador.\n",
      "\n",
      "Generando predicciones...\n",
      "\n",
      "Distribución de predicciones:\n",
      "Attrition\n",
      "No     1236\n",
      "Yes     234\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Predicciones guardadas en 'predicciones.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Importamos los datos de entrenamiento\n",
    "datos_generales_originales = pd.read_csv('./attrition_availabledata_10.csv.gz')\n",
    "print(\"Datos originales de entrenamiento cargados para ajustar el preprocesador.\")\n",
    "\n",
    "\n",
    "# Para el conjunto de competición, eliminamos las mismas columnas que eliminamos en el entrenamiento\n",
    "datos_generales_originales['Attrition'] = datos_generales_originales['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "X_entrenamiento = datos_generales_originales.drop(columns=['Attrition', 'EmployeeID', 'Over18', 'EmployeeCount', 'StandardHours'])\n",
    "\n",
    "# REDEFINIMOS MANUALMENTE EL PREPROCESADOR UTILIZADO EN EL BEST MODEL\n",
    "\n",
    "categorical_features = ['Department', 'JobRole', 'EducationField']\n",
    "ordinal_features = ['BusinessTravel', 'Gender', 'MaritalStatus']\n",
    "# numerical_features = X_entrenamiento.select_dtypes(include=['int64','float64']).columns.tolist() # No se usa explícitamente aquí\n",
    "valores_ordinales = [\n",
    "    ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'],   # BusinessTravel\n",
    "    ['Male', 'Female'],                                     # Gender\n",
    "    ['Single', 'Married', 'Divorced']                       # MaritalStatus \n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('ord', OrdinalEncoder(categories=valores_ordinales, handle_unknown='use_encoded_value', unknown_value=-1), ordinal_features)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "# Ajustamos el preprocesador con TODOS los datos de X \n",
    "preprocessor.fit(X_entrenamiento)\n",
    "\n",
    "# --- PASO 2: CargaMOS datos de competición y modelo final ---\n",
    "datos_test_competicion = pd.read_csv('./attrition_competition_10.csv.gz')\n",
    "modelo_final = joblib.load('modelo_final.pkl')\n",
    "\n",
    "\n",
    "columnas_a_eliminar_test = [\"EmployeeID\", \"EmployeeCount\", \"Over18\", \"StandardHours\"]\n",
    "\n",
    "# Asegúrate de que datos_test_competicion exista y sea el DataFrame correcto\n",
    "datos_test_competicion_limpios = datos_test_competicion.drop(columns=columnas_a_eliminar_test)\n",
    "\n",
    "# No eliminamos 'Attrition' aquí porque no existe en los datos de competición\n",
    "\n",
    "# Aplicar el preprocesador ajustado a los datos de competición\n",
    "datos_test_transformados = preprocessor.transform(datos_test_competicion_limpios)\n",
    "\n",
    "# Convertimos a DataFrame para facilitar la manipulación\n",
    "columnas_prefijadas = preprocessor.get_feature_names_out()\n",
    "datos_test_listos_para_predecir = pd.DataFrame(datos_test_transformados, columns=columnas_prefijadas)\n",
    "\n",
    "# --- PASO 3: Generamos las Predicciones ---\n",
    "print(\"\\nGenerando predicciones...\")\n",
    "\n",
    "# Pasamos el DataFrame con los nombres de columna CORRECTOS (prefijados)\n",
    "y_pred_test = modelo_final.predict(datos_test_listos_para_predecir)\n",
    "\n",
    "# Creamos un DataFrame con las predicciones y el EmployeeID original\n",
    "df_predicciones = pd.DataFrame({\n",
    "    'EmployeeID': datos_test_competicion['EmployeeID'], # Usamos el ID original\n",
    "    'Attrition': y_pred_test # La columna de predicción\n",
    "})\n",
    "\n",
    "# Mapeamos de nuevo a 'Yes'/'No' si es necesario para el formato de salida\n",
    "df_predicciones['Attrition'] = df_predicciones['Attrition'].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "print(f\"\\nDistribución de predicciones:\\n{df_predicciones['Attrition'].value_counts()}\")\n",
    "\n",
    "# Guardamos las predicciones\n",
    "output_filename = \"predicciones.csv\"\n",
    "df_predicciones.to_csv(output_filename, index=False)\n",
    "print(f\"\\nPredicciones guardadas en '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tarea Adicional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta tarea adicional, hemos decicido utilizar la herramienta SHAP, para interpretar nuestro modelo final.\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) es una herramienta basada en la teoría de juegos que permite cuantificar la contribución de cada variable a la predicción de un modelo. Entre sus principales ventajas destacan:\n",
    "\n",
    "* **Interpretabilidad Local y Global**: SHAP ofrece explicaciones tanto a nuvel individual (por cada predicción) como a nivel global (importancia de las variables a lo largo de todo el conjunto). Esto permite identificar cómo cada característica influye en cada decisión del modelo.\n",
    "\n",
    "* **Consistencia y solidez**: Los valores de Shapley garantizan que la contribución de cada característica se mida de forma justa, lo que otorga una interpretación coherente y consistente.\n",
    "\n",
    "* **Modelo-agnóstico**: A diferencia de otros métodos que se basan en la estructura interna del modelo (por ejemplo, la importancia basada en la impureza de los árboles en RandomForest), SHAP puede aplicarse a cualquier modelo.\n",
    "\n",
    "* **Transparencia**: Integrar SHAP en el análisis del modelo permite detectar posibles sesgos o relaciones inesperadas entre variables, lo cual es fundamental para generar confianza en la toma de decisiones basadas en inteligencia artificial.\n",
    "\n",
    "Realizar esta tarea extra con SHAP resulta especialmente interesante en comparación con construir otro modelo como un RandomForest o una red neuronal. Aunque estos modelos pueden ofrecer buenos resultados, la interpretación de sus resultados (por ejemplo, mediante la importancia de variables basada en el Gini o técnicas de regularización) suele ser menos precisa y profunda. En cambio, al interpretar el modelo SVM seleccionado con SHAP, se obtiene una explicación detallada y cuantitativa de la influencia de cada característica en la predicción, lo cual añade un valor extra al análisis, especialmente en contextos donde la explicabilidad es crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Código para usar SHAP en nuestro modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Seleccionar una muestra representativa del conjunto preprocesado para el fondo (background)\n",
    "# Reducir el tamaño del fondo para acelerar el cálculo\n",
    "X_background = X_preprocessed.sample(20, random_state=42)\n",
    "\n",
    "# Definir la función de predicción asegurándonos de que se pasan los nombres de las columnas\n",
    "def model_predict(data):\n",
    "    # Convertir a DataFrame si es necesario\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data, columns=columnas_preprocesadas)\n",
    "    return final_pipeline.predict_proba(data)[:, 1]\n",
    "\n",
    "# Crear el explicador con KernelExplainer usando el fondo reducido\n",
    "explainer = shap.KernelExplainer(model_predict, X_background)\n",
    "\n",
    "# Seleccionar un subconjunto reducido de datos para explicar\n",
    "X_explain = X_preprocessed.sample(10, random_state=42)\n",
    "\n",
    "# Calcular los valores SHAP para el subconjunto seleccionado, limitando nsamples para acelerar el proceso\n",
    "shap_values = explainer.shap_values(X_explain, nsamples=50)\n",
    "\n",
    "# Visualizar el resumen de los valores SHAP para identificar la importancia de las variables\n",
    "shap.summary_plot(shap_values, X_explain, feature_names=columnas_preprocesadas)\n",
    "plt.show()\n",
    "\n",
    "# Explicación local de una instancia en particular\n",
    "i = 0  # índice de la instancia a explicar\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[i], X_explain.iloc[i], feature_names=columnas_preprocesadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gráfica SHAP permite ver qué variables han influido más en las predicciones del modelo SVM sobre la variable Attrition. También muestra cómo valores altos o bajos de cada variable afectan individualmente a cada empleado.\n",
    "\n",
    "En este caso, la variable más influyente es remainder__TotalWorkingYears, lo que indica que el número total de años trabajados es clave en la decisión. Empleados con más años suelen tener valores SHAP negativos, lo que reduce la probabilidad de abandono. También destacan variables como remainder__hrs, DistanceFromHome o TrainingTimesLastYear. Por ejemplo, empleados que viven lejos tienden a tener más probabilidad de dejar la empresa, mientras que recibir más formación puede asociarse a menor riesgo.\n",
    "\n",
    "Las variables categóricas como el estado civil o el rol profesional (JobRole_Manager, MaritalStatus) también influyen, aunque en menor medida. Tener un cargo alto o estar casado parece relacionarse con mayor estabilidad.\n",
    "\n",
    "En general, el gráfico muestra que la experiencia, la distancia al trabajo y otros factores numéricos son los que más afectan al resultado. Se observan patrones coherentes: valores altos en algunas variables empujan la predicción hacia Attrition = 1, mientras que en otras hacen lo contrario. Esto permite confiar más en el modelo y entender mejor sus decisiones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
