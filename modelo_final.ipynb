{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *MODELO FINAL*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Selección del Mejor Modelo\n",
    "Tras evaluar distintos modelos (KNN, Árboles de Decisión, Regresión Logística, SVM, etc) se comprobó que el SVM con Kernel RBF y los hiperparámetros óptimos:\n",
    "* C=10\n",
    "* gamma = 'scale'\n",
    "* kernel = 'rbf'\n",
    "\n",
    "presenta el mejor desempeño en términos de Balanced Accuracy en el conjunto de validación interna. Esto lo convierte en nuestro candidato para el modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluación Outer y Estimación del Desempeño futuro\n",
    "La estrategia de evaluación outer consiste en separar los datos en dos partes:\n",
    "\n",
    "* Train (2/3): Para realizar el ajuste y selección de modelos\n",
    "* Test (1/3): Para obtener una estimación real de rendimiento que tendría el modelo en una competición\n",
    "\n",
    "Aunque durante la práctica se ha usado esta partición para evaluar el desempeño, en el paso final se reentrena al modelo usando todos los datos disponibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Entrenamiento final y Guardado del Modelo\n",
    "En este paso se reentrena al modelo SVM Final utilizando todos los datos. Se aplica un preprocesado antes de entenar el clasificador. Finalmente guardamos el modelo en modelo_final.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy en el conjunto de entrenamiento: 0.9979\n",
      "Modelo final guardado en 'modelo_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# ---------------------------\n",
    "# 3.1. Cargar y Preprocesar los Datos\n",
    "# ---------------------------\n",
    "# Cargamos los datos disponibles de entrenamiento y el dataset de competición\n",
    "datos_generales = pd.read_csv('./attrition_availabledata_10.csv.gz')\n",
    "datos_test = pd.read_csv('./attrition_competition_10.csv.gz')  # Datos para el test de la competición\n",
    "\n",
    "# Convertimos la variable objetivo a numérica: 'Yes' -> 1, 'No' -> 0\n",
    "datos_generales['Attrition'] = datos_generales['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Eliminamos columnas que no aportan información (IDs, columnas constantes, etc.)\n",
    "X = datos_generales.drop(columns=['Attrition', 'EmployeeID', 'Over18', 'EmployeeCount', 'StandardHours'])\n",
    "y = datos_generales['Attrition']\n",
    "\n",
    "# Definimos los nombres de variables según su tipo (estas definiciones se han usado en el preprocesado)\n",
    "categorical_features = ['Department', 'JobRole', 'EducationField']\n",
    "ordinal_features = ['BusinessTravel', 'Gender', 'MaritalStatus']\n",
    "# Nota: el resto de las variables numéricas se mantienen sin transformación adicional\n",
    "valores_ordinales = [\n",
    "    ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'],\n",
    "    ['Male', 'Female'],\n",
    "    ['Single', 'Married', 'Divorced']\n",
    "]\n",
    "\n",
    "# Creamos el preprocesador para transformar variables categóricas y ordinales\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),  # Variables categóricas sin orden\n",
    "        ('ord', OrdinalEncoder(categories=valores_ordinales), ordinal_features)  # Variables ordinales\n",
    "    ],\n",
    "    remainder='passthrough'  # El resto de variables (numéricas) se mantienen\n",
    ")\n",
    "\n",
    "# Aplicamos el preprocesado a todo el dataset de entrenamiento\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "# Obtenemos nombres de columnas tras la transformación para posibles análisis posteriores\n",
    "columnas_preprocesadas = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Convertimos el resultado a DataFrame (opcional, para visualización)\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed, columns=columnas_preprocesadas)\n",
    "\n",
    "# ---------------------------\n",
    "# 3.2. Entrenamiento del Modelo Final\n",
    "# ---------------------------\n",
    "# Definimos el pipeline final: imputación (por si acaso), escalado y SVM con hiperparámetros óptimos\n",
    "final_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('svm', SVC(C=10, gamma='scale', kernel='rbf', probability=True))  # Se incluye probability=True si se requieren probabilidades\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo final con la totalidad de los datos preprocesados\n",
    "final_pipeline.fit(X_preprocessed, y)\n",
    "\n",
    "# Realizamos predicciones en el conjunto de entrenamiento\n",
    "y_pred = final_pipeline.predict(X_preprocessed)\n",
    "\n",
    "# Calculamos la balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(y, y_pred)\n",
    "print(f\"Balanced Accuracy en el conjunto de entrenamiento: {balanced_accuracy:.4f}\")\n",
    "\n",
    "# Guardamos el modelo final en un fichero 'modelo_final.pkl'\n",
    "with open('modelo_final.pkl', 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "print(\"Modelo final guardado en 'modelo_final.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Generación de Predicciones para la Competición\n",
    "El siguiente paso es utilizar el modelo final para generar predicciones sobre el conjunto de datos de la competición. Para ello se debe aplicar el mismo preprocesado que a los datos de entrenamiento. El fichero resultante se guardará como predicciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones guardadas en 'predicciones.csv'\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 4.1. Preprocesamiento de los Datos de la Competición\n",
    "# ---------------------------\n",
    "# Para el conjunto de competición, eliminamos las mismas columnas que en el entrenamiento.\n",
    "# Se asume que el dataset de competición no contiene la variable 'Attrition'\n",
    "X_competicion = datos_test.drop(columns=['EmployeeID', 'Over18', 'EmployeeCount', 'StandardHours'])\n",
    "\n",
    "# Aplicamos el preprocesado usando el preprocessor ya ajustado (fit) en el conjunto de entrenamiento\n",
    "X_competicion_preprocessed = preprocessor.transform(X_competicion)\n",
    "# Convertimos a DataFrame para mayor claridad\n",
    "X_competicion_preprocessed = pd.DataFrame(X_competicion_preprocessed, columns=columnas_preprocesadas)\n",
    "\n",
    "# ---------------------------\n",
    "# 4.2. Generar Predicciones\n",
    "# ---------------------------\n",
    "# Utilizamos el modelo final para predecir las clases (o probabilidades si se requiere)\n",
    "predicciones = final_pipeline.predict(X_competicion_preprocessed)\n",
    "\n",
    "# Si se desea guardar además las probabilidades, se puede obtener:\n",
    "# prob_pred = final_pipeline.predict_proba(X_competicion_preprocessed)\n",
    "\n",
    "# Creamos un DataFrame con las predicciones\n",
    "df_predicciones = pd.DataFrame({\n",
    "    'Predicted_Attrition': predicciones\n",
    "})\n",
    "\n",
    "# Guardamos el DataFrame en un fichero CSV\n",
    "df_predicciones.to_csv('predicciones.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "X_background = shap.sample(X_preprocessed, 1, random_state=42)  # Toma 100 instancias al azar\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(\n",
    "    lambda x: final_pipeline.predict_proba(x),\n",
    "    X_background,\n",
    "    link=\"logit\"\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "shap_values = explainer.shap_values(X_preprocessed)\n",
    "\n",
    "shap.summary_plot(shap_values[1], X_preprocessed)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
