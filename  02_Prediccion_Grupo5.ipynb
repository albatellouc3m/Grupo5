{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Modelo Final**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Selección del Mejor Modelo\n",
    "Tras evaluar distintos modelos (KNN, Árboles de Decisión, Regresión Logística, SVM, etc) se comprobó que el SVM con Kernel RBF y los hiperparámetros óptimos:\n",
    "* C=10\n",
    "* gamma = 'scale'\n",
    "* kernel = 'rbf'\n",
    "\n",
    "presenta el mejor desempeño en términos de Balanced Accuracy en el conjunto de validación interna. Esto lo convierte en nuestro candidato para el modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.Generación de Predicciones para la Competición\n",
    "El siguiente paso es utilizar el modelo final para generar predicciones sobre el conjunto de datos de la competición. Para ello se debe aplicar el mismo preprocesado que a los datos de entrenamiento. El fichero resultante se guardará como predicciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales de entrenamiento cargados para ajustar el preprocesador.\n",
      "\n",
      "Generando predicciones...\n",
      "\n",
      "Distribución de predicciones:\n",
      "Attrition\n",
      "No     1236\n",
      "Yes     234\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Predicciones guardadas en 'predicciones_Grupo5.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Importamos los datos de entrenamiento\n",
    "datos_generales_originales = pd.read_csv('./attrition_availabledata_10.csv.gz')\n",
    "print(\"Datos originales de entrenamiento cargados para ajustar el preprocesador.\")\n",
    "\n",
    "\n",
    "# Para el conjunto de competición, eliminamos las mismas columnas que eliminamos en el entrenamiento\n",
    "datos_generales_originales['Attrition'] = datos_generales_originales['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "X_entrenamiento = datos_generales_originales.drop(columns=['Attrition', 'EmployeeID', 'Over18', 'EmployeeCount', 'StandardHours'])\n",
    "\n",
    "# REDEFINIMOS MANUALMENTE EL PREPROCESADOR UTILIZADO EN EL BEST MODEL\n",
    "\n",
    "categorical_features = ['Department', 'JobRole', 'EducationField']\n",
    "ordinal_features = ['BusinessTravel', 'Gender', 'MaritalStatus']\n",
    "\n",
    "valores_ordinales = [\n",
    "    ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'],   # BusinessTravel\n",
    "    ['Male', 'Female'],                                     # Gender\n",
    "    ['Single', 'Married', 'Divorced']                       # MaritalStatus \n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('ord', OrdinalEncoder(categories=valores_ordinales, handle_unknown='use_encoded_value', unknown_value=-1), ordinal_features)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "# Ajustamos el preprocesador con TODOS los datos de X \n",
    "preprocessor.fit(X_entrenamiento)\n",
    "\n",
    "# --- PASO 2: CargaMOS datos de competición y modelo final ---\n",
    "datos_test_competicion = pd.read_csv('./attrition_competition_10.csv.gz')\n",
    "modelo_final = joblib.load('modelo_final_Grupo5.pkl')\n",
    "\n",
    "\n",
    "columnas_a_eliminar_test = [\"EmployeeID\", \"EmployeeCount\", \"Over18\", \"StandardHours\"]\n",
    "\n",
    "# Asegúrate de que datos_test_competicion exista y sea el DataFrame correcto\n",
    "datos_test_competicion_limpios = datos_test_competicion.drop(columns=columnas_a_eliminar_test)\n",
    "\n",
    "# No eliminamos 'Attrition' aquí porque no existe en los datos de competición\n",
    "\n",
    "# Aplicar el preprocesador ajustado a los datos de competición\n",
    "datos_test_transformados = preprocessor.transform(datos_test_competicion_limpios)\n",
    "\n",
    "# Convertimos a DataFrame para facilitar la manipulación\n",
    "columnas_prefijadas = preprocessor.get_feature_names_out()\n",
    "datos_test_listos_para_predecir = pd.DataFrame(datos_test_transformados, columns=columnas_prefijadas)\n",
    "\n",
    "# --- PASO 3: Generamos las Predicciones ---\n",
    "print(\"\\nGenerando predicciones...\")\n",
    "\n",
    "# Pasamos el DataFrame con los nombres de columna CORRECTOS (prefijados)\n",
    "y_pred_test = modelo_final.predict(datos_test_listos_para_predecir)\n",
    "\n",
    "# Creamos un DataFrame con las predicciones y el EmployeeID original\n",
    "df_predicciones = pd.DataFrame({\n",
    "    'EmployeeID': datos_test_competicion['EmployeeID'], # Usamos el ID original\n",
    "    'Attrition': y_pred_test # La columna de predicción\n",
    "})\n",
    "\n",
    "# Mapeamos de nuevo a 'Yes'/'No' si es necesario para el formato de salida\n",
    "df_predicciones['Attrition'] = df_predicciones['Attrition'].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "print(f\"\\nDistribución de predicciones:\\n{df_predicciones['Attrition'].value_counts()}\")\n",
    "\n",
    "# Guardamos las predicciones\n",
    "output_filename = \"predicciones_Grupo5.csv\"\n",
    "df_predicciones.to_csv(output_filename, index=False)\n",
    "print(f\"\\nPredicciones guardadas en '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Tarea Adicional**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta tarea adicional, hemos decicido utilizar la herramienta SHAP, para interpretar nuestro modelo final.\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) es una herramienta basada en la teoría de juegos que permite cuantificar la contribución de cada variable a la predicción de un modelo. Entre sus principales ventajas destacan:\n",
    "\n",
    "* **Interpretabilidad Local y Global**: SHAP ofrece explicaciones tanto a nuvel individual (por cada predicción) como a nivel global (importancia de las variables a lo largo de todo el conjunto). Esto permite identificar cómo cada característica influye en cada decisión del modelo.\n",
    "\n",
    "* **Consistencia y solidez**: Los valores de Shapley garantizan que la contribución de cada característica se mida de forma justa, lo que otorga una interpretación coherente y consistente.\n",
    "\n",
    "* **Modelo-agnóstico**: A diferencia de otros métodos que se basan en la estructura interna del modelo (por ejemplo, la importancia basada en la impureza de los árboles en RandomForest), SHAP puede aplicarse a cualquier modelo.\n",
    "\n",
    "* **Transparencia**: Integrar SHAP en el análisis del modelo permite detectar posibles sesgos o relaciones inesperadas entre variables, lo cual es fundamental para generar confianza en la toma de decisiones basadas en inteligencia artificial.\n",
    "\n",
    "Realizar esta tarea extra con SHAP resulta especialmente interesante en comparación con construir otro modelo como un RandomForest o una red neuronal. Aunque estos modelos pueden ofrecer buenos resultados, la interpretación de sus resultados (por ejemplo, mediante la importancia de variables basada en el Gini o técnicas de regularización) suele ser menos precisa y profunda. En cambio, al interpretar el modelo SVM seleccionado con SHAP, se obtiene una explicación detallada y cuantitativa de la influencia de cada característica en la predicción, lo cual añade un valor extra al análisis, especialmente en contextos donde la explicabilidad es crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Código para usar SHAP en nuestro modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, debemos instalar la libreria de shap en nuestro entorno virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in ./.venv/lib/python3.12/site-packages (0.47.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from shap) (2.1.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from shap) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from shap) (1.6.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in ./.venv/lib/python3.12/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in ./.venv/lib/python3.12/site-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in ./.venv/lib/python3.12/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in ./.venv/lib/python3.12/site-packages (from shap) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.12/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from shap) (4.13.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./.venv/lib/python3.12/site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [00:41<00:48,  2.23it/s]"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Usamos el DataFrame X_entrenamiento para el preprocesamiento\n",
    "X_entrenamiento_transformado_np = preprocessor.transform(X_entrenamiento) # Sale como NumPy array\n",
    "\n",
    "columnas_preprocesadas = preprocessor.get_feature_names_out()\n",
    "\n",
    "X_entrenamiento_preprocesado = pd.DataFrame(X_entrenamiento_transformado_np, columns=columnas_preprocesadas)\n",
    "\n",
    "# Obtenemos los nombres de las columnas DESPUÉS del preprocesamiento\n",
    "\n",
    "# Seleccionar una muestra representativa del conjunto preprocesado para el fondo (background)\n",
    "# Reducir el tamaño del fondo para acelerar el cálculo\n",
    "X_background = X_entrenamiento_preprocesado.sample(100, random_state=42)\n",
    "\n",
    "# Definir la función de predicción asegurándonos de que se pasan los nombres de las columnas\n",
    "def model_predict_proba(data):\n",
    "    # KernelExplainer puede pasar un NumPy array, lo convertimos a DataFrame\n",
    "    # con las columnas correctas ANTES de pasarlo al modelo.\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data_df = pd.DataFrame(data, columns=columnas_preprocesadas)\n",
    "    else:\n",
    "        data_df = data #\n",
    "    # Accedemos al mejor estimador y usamos .predict()\n",
    "    return modelo_final.best_estimator_.predict(data_df)\n",
    "\n",
    "# Crear el explicador con KernelExplainer usando el fondo reducido\n",
    "explainer = shap.KernelExplainer(model_predict_proba, X_background)\n",
    "\n",
    "# Seleccionar un subconjunto reducido de datos para explicar\n",
    "X_explain = X_entrenamiento_preprocesado.sample(200, random_state=42)\n",
    "\n",
    "# Calcular los valores SHAP para el subconjunto seleccionado, limitando nsamples para acelerar el proceso\n",
    "shap_values = explainer.shap_values(X_explain, nsamples=100)\n",
    "\n",
    "# Visualizar el resumen de los valores SHAP para identificar la importancia de las variables\n",
    "shap.summary_plot(shap_values, X_explain, feature_names=columnas_preprocesadas)\n",
    "plt.show()\n",
    "\n",
    "# Explicación local de una instancia en particular\n",
    "i = 0  # índice de la instancia a explicar\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[i], X_explain.iloc[i], feature_names=columnas_preprocesadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta representación SHAP nos da una idea de qué aspectos considera más relevantes el modelo SVC al predecir la Attrition (si un trabajador se va o se queda). Aparte, nos deja ver cómo un valor alto o bajo en cada factor afecta a empleados concretos.\n",
    "\n",
    "Lo más determinante sigue siendo, de manera uniforme, *remainderhrs*. Niveles altos (puntos rojos) elevan de forma notable la opción de marcha (SHAP positivos), mientras que niveles reducidos (azules) la minimizan (SHAP negativos).\n",
    "\n",
    "Tras este aspecto esencial, vemos un conjunto de variables de importancia continua, aunque su orden justo podría variar un poco entre usos o con distintas muestras. Entre las más destacadas en este estudio están *ord_MaritalStatus* (estar soltero, azul , eleva mucho el riesgo), *remainder_TotalWorkingYears* (más experiencia, rojo, reduce el peligro), *remainder_TrainingTimesLastYear* (más formación, rojo, parece elevar el peligro, un punto curioso para remarcar) y *remainder_JobSatisfaction* (poca satisfacción, azul, eleva el peligro). La variable *ord_BusinessTravel* (viajar mucho, rojo, eleva el peligro) también tiende a salir con una influencia importante.\n",
    "\n",
    "Otras variables como el tiempo desde el último ascenso (*remainder_YearsSinceLastPromotion*), la satisfacción con el entorno (*remainder_EnvironmentSatisfaction*), formar parte de ciertos departamentos (p. ej. , *cat_Department_Sales*) y la edad (*remainder_Age*) también enseñan influencia relevante en las predicciones del modelo, pese a que su sitio exacto en la lista puede cambiar.\n",
    "\n",
    "En líneas generales, el análisis SHAP da a entender que, para el modelo SVC, aspectos como las horas de trabajo, el estado civil, el recorrido reunido, la formación reciente, la satisfacción en el trabajo y los viajes son cruciales para anticipar la rotación. Si bien la importancia relativa justa puede presentar pequeñas variaciones, los patrones notados (cómo niveles altos o reducidos de estas variables afectan la predicción) son coherentes y lógicos en su mayoría. Esto nos ayuda a comprender mejor cómo decide el modelo y a fiarnos de sus resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
